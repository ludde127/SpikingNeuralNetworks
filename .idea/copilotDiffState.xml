<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/src/main.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/main.rs" />
              <option name="originalContent" value="use graphviz_rust::print;&#10;use rand::{thread_rng, Rng, SeedableRng};&#10;use plotters::prelude::*;&#10;use rand::rngs::StdRng;&#10;// Added for reward plotting&#10;use crate::network::{Network, VisualizeNetwork};&#10;use crate::neuron::NeuronBehavior;&#10;use crate::simulation::Simulation;&#10;&#10;mod constants;&#10;mod data;&#10;mod network;&#10;mod neuron;&#10;mod spike_event;&#10;mod synapse;&#10;mod simulation;&#10;mod utils;&#10;mod reward_system;&#10;mod datastructures;&#10;&#10;/// Plots a 1D vector of f32 data as a line chart.&#10;fn plot_reward_over_time(&#10;    data: &amp;[f32],&#10;    path: &amp;str,&#10;    title: &amp;str,&#10;) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {&#10;    if data.is_empty() {&#10;        println!(&quot;No reward data to plot.&quot;);&#10;        return Ok(());&#10;    }&#10;&#10;    let root = BitMapBackend::new(path, (1024, 768)).into_drawing_area();&#10;    root.fill(&amp;WHITE)?;&#10;&#10;    // Find min and max reward for y-axis&#10;    let max_val = data.iter().cloned().fold(f32::NEG_INFINITY, f32::max);&#10;    let min_val = data.iter().cloned().fold(f32::INFINITY, f32::min);&#10;&#10;    // Add some padding, but cap at reward limits&#10;    let y_max = (max_val + 0.2).min(1.0);&#10;    let y_min = (min_val - 0.2).max(-1.0);&#10;&#10;    let mut chart = ChartBuilder::on(&amp;root)&#10;        .caption(title, (&quot;sans-serif&quot;, 40).into_font())&#10;        .margin(10)&#10;        .x_label_area_size(40)&#10;        .y_label_area_size(40)&#10;        .build_cartesian_2d(0..data.len(), y_min..y_max)?;&#10;&#10;    chart.configure_mesh()&#10;        .x_desc(&quot;Trial Batch&quot;)&#10;        .y_desc(&quot;Average Reward&quot;)&#10;        .draw()?;&#10;&#10;    chart.draw_series(LineSeries::new(&#10;        data.iter().enumerate().map(|(x, y)| (x, *y)),&#10;        &amp;BLUE&#10;    ))?;&#10;&#10;    root.present()?;&#10;    println!(&quot;Reward plot saved to {}&quot;, path);&#10;    Ok(())&#10;}&#10;&#10;&#10;fn main() {&#10;    println!(&quot;Spiking Neural Network Simulation&quot;);&#10;    let mut rng = StdRng::seed_from_u64(42); // Fixed seed for reproducibility&#10;    let mut rng = thread_rng(); // Non-deterministic seed for variability&#10;    let mut network = Network::create_dense(3, &amp;mut rng);&#10;    let mut simulation = Simulation::new(1.0, network.neurons.clone());&#10;&#10;    network.plot_synapse_weights(&quot;synapse_weights_start.png&quot;).unwrap();&#10;&#10;    const INPUT_NEURON_A_IDX: usize = 0; // &quot;Go&quot; signal&#10;    const INPUT_NEURON_B_IDX: usize = 1; // &quot;No-Go&quot; signal&#10;    const OUTPUT_NEURON_IDX: usize = 2; // Target output&#10;    const REWARD_MAGNITUDE: f32 = 1.0; // Changed to f32&#10;&#10;    const NUM_TRIALS: u32 = 20_000;&#10;    const TRIAL_WINDOW_STEPS: u32 = 25;&#10;&#10;    println!(&quot;Starting simulation... Target: Neuron {} spikes for Input {}, not for Input {}.&quot;,&#10;             OUTPUT_NEURON_IDX, INPUT_NEURON_A_IDX, INPUT_NEURON_B_IDX);&#10;    println!(&quot;Running {} trials, each with a {}-step response window.&quot;, NUM_TRIALS, TRIAL_WINDOW_STEPS);&#10;&#10;&#10;    let mut total_reward_batch = 0.0f32;&#10;    let mut all_trial_rewards: Vec&lt;f32&gt; = Vec::new();&#10;    let mut batch_avg_rewards: Vec&lt;f32&gt; = Vec::new();&#10;    // New series: RewardSystem EMA average per trial (sampled after applying reward)&#10;    let mut reward_system_avg_over_trials: Vec&lt;f32&gt; = Vec::new();&#10;    const BATCH_SIZE: u32 = 50;&#10;&#10;    for trial in 0..NUM_TRIALS {&#10;        let (input_idx, is_go_signal) = if rng.gen_bool(0.5) {&#10;            (INPUT_NEURON_A_IDX, true)&#10;        } else {&#10;            (INPUT_NEURON_B_IDX, false)&#10;        };&#10;&#10;        // Get spike time *before* the trial starts&#10;        let last_spike_time_before_trial = {&#10;            network.neurons[OUTPUT_NEURON_IDX].read().unwrap().time_of_last_fire()&#10;        };&#10;&#10;        // pct_rand should decrease exponentially over trials&#10;        let pct_rand = (-0.3 * (trial as f32)).exp();&#10;&#10;        // --- This is the inner trial loop ---&#10;        simulation.step();&#10;        //simulation.random_noise(0.0, 1.0, 1.0, &amp;mut rng);&#10;        for _ in 0..TRIAL_WINDOW_STEPS {&#10;            simulation.input_external_stimuli(network.neurons[input_idx].clone(), 1.0);&#10;            //if pct_rand &gt; 0.0001 {&#10;            //    simulation.random_noise(-pct_rand*5.0, pct_rand*5.0, pct_rand, &amp;mut rng);&#10;            //}&#10;            simulation.step();&#10;            // DO NOT apply reward here&#10;        }&#10;        // --- End of inner trial loop ---&#10;&#10;        // Now, check the *overall* outcome of the trial&#10;        println!(&quot;Evaluating trial {}: Input Neuron {}, Go Signal: {}, Started at {}&quot;, trial + 1, input_idx, is_go_signal, last_spike_time_before_trial);&#10;&#10;        for fire in network.neurons[OUTPUT_NEURON_IDX].read().unwrap().last_spike_times.iter().filter(|p| p.time &gt; last_spike_time_before_trial) {&#10;            println!(&quot;  Output neuron spike at time {:.2} ms, strength: {}&quot;, fire.time, fire.membrane_potential_at_spike);&#10;        }&#10;&#10;        let output_spiked_during_trial = {&#10;            network.neurons[OUTPUT_NEURON_IDX].read().unwrap().time_of_last_fire() &gt; last_spike_time_before_trial&#10;        };&#10;        //println!(&quot;Output spiked during trial: {}&quot;, output_spiked_during_trial);&#10;&#10;        let reward: f32;&#10;        if is_go_signal {&#10;            if output_spiked_during_trial {&#10;                reward = REWARD_MAGNITUDE; // Correct: &quot;Go&quot; and it spiked&#10;            } else {&#10;                reward = -REWARD_MAGNITUDE; // Correct: &quot;Go&quot; and it didn't spike&#10;            }&#10;        } else { // is_no_go_signal&#10;            if output_spiked_during_trial {&#10;                reward = -REWARD_MAGNITUDE; // Correct: &quot;No-Go&quot; and it spiked&#10;            } else {&#10;                reward = REWARD_MAGNITUDE; // Correct: &quot;No-Go&quot; and it didn't spike&#10;            }&#10;        }&#10;&#10;        // Apply the *single* reward for the *entire* trial&#10;        simulation.reward(reward);&#10;&#10;        // Capture RewardSystem EMA average immediately after this trial's reward&#10;        reward_system_avg_over_trials.push(simulation.average_reward());&#10;&#10;        // This intra-trial result tracking is fine, but it was just for logging.&#10;        // We'll use the final reward for logging.&#10;        let intra_trial_result = reward;&#10;        all_trial_rewards.push(intra_trial_result);&#10;        total_reward_batch += intra_trial_result;&#10;&#10;        if (trial + 1) % BATCH_SIZE == 0 {&#10;            let avg_reward = total_reward_batch / (BATCH_SIZE as f32);&#10;            println!(&quot;Trials {}-{}: Average Reward = {:.2}&quot;, trial + 1 - BATCH_SIZE, trial + 1, avg_reward);&#10;            batch_avg_rewards.push(avg_reward);&#10;            total_reward_batch = 0.0f32;&#10;        }&#10;    }&#10;&#10;    println!(&quot;Simulation finished.&quot;);&#10;&#10;    if let Err(e) = plot_reward_over_time(&#10;        &amp;batch_avg_rewards,&#10;        &quot;reward_over_time.png&quot;,&#10;        &quot;Average Reward per Batch&quot;,&#10;    ) {&#10;        eprintln!(&quot;Error plotting reward: {}&quot;, e);&#10;    }&#10;&#10;    // Also plot the RewardSystem EMA average over trials&#10;    if let Err(e) = plot_reward_over_time(&#10;        &amp;reward_system_avg_over_trials,&#10;        &quot;reward_system_average_over_time.png&quot;,&#10;        &quot;EMA Average Reward (RewardSystem)&quot;,&#10;    ) {&#10;        eprintln!(&quot;Error plotting RewardSystem average: {}&quot;, e);&#10;    }&#10;&#10;    // New: plot delta error per learning step (one point per reward application)&#10;    let delta_errors: Vec&lt;f32&gt; = simulation.delta_error_history().to_vec();&#10;    if let Err(e) = plot_reward_over_time(&#10;        &amp;delta_errors,&#10;        &quot;delta_error_over_time.png&quot;,&#10;        &quot;Delta Error per Learning Step&quot;,&#10;    ) {&#10;        eprintln!(&quot;Error plotting delta error: {}&quot;, e);&#10;    }&#10;    // ---&#10;&#10;    // Calculate and print moving average of rewards&#10;    let moving_avg_window = 100; // This is 100 *trials*, not batches&#10;    if all_trial_rewards.len() &gt; moving_avg_window {&#10;        println!(&quot;Moving average of reward (window={}):&quot;, moving_avg_window);&#10;        let moving_averages: Vec&lt;f32&gt; = all_trial_rewards // Changed to f32&#10;            .windows(moving_avg_window)&#10;            .map(|w| w.iter().sum::&lt;f32&gt;() / (moving_avg_window as f32)) // Changed to f32&#10;            .collect();&#10;&#10;        // Print a subset of moving averages to avoid flooding console&#10;        for (i, avg) in moving_averages.iter().enumerate().step_by(moving_avg_window) {&#10;            println!(&quot;  Trials {}-{}: {:.2}&quot;, i, i + moving_avg_window, avg);&#10;        }&#10;    }&#10;&#10;    network.plot_synapse_weights(&quot;synapse_weights_end.png&quot;).unwrap();&#10;    network.describe();&#10;&#10;    println!(&quot;\nCheck synapse_weights_start.png, synapse_weights_end.png, and reward_over_time.png.&quot;);&#10;    println!(&quot;If learning occurred, you should see a rising trend in the average rewards.&quot;);&#10;    println!(&quot;The weights plot might show stronger connections from {} -&gt; {}&quot;, INPUT_NEURON_A_IDX, OUTPUT_NEURON_IDX);&#10;    println!(&quot;and weaker (or inhibitory) connections from {} -&gt; {}&quot;, INPUT_NEURON_B_IDX, OUTPUT_NEURON_IDX);&#10;}&#10;" />
              <option name="updatedContent" value="use rand::{thread_rng, Rng};&#10;use plotters::prelude::*;&#10;// Added for reward plotting&#10;use crate::network::{Network, VisualizeNetwork};&#10;use crate::neuron::NeuronBehavior;&#10;use crate::simulation::Simulation;&#10;&#10;mod constants;&#10;mod data;&#10;mod network;&#10;mod neuron;&#10;mod spike_event;&#10;mod synapse;&#10;mod simulation;&#10;mod utils;&#10;mod reward_system;&#10;mod datastructures;&#10;&#10;/// Plots a 1D vector of f32 data as a line chart.&#10;fn plot_reward_over_time(&#10;    data: &amp;[f32],&#10;    path: &amp;str,&#10;    title: &amp;str,&#10;) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {&#10;    if data.is_empty() {&#10;        println!(&quot;No reward data to plot.&quot;);&#10;        return Ok(());&#10;    }&#10;&#10;    let root = BitMapBackend::new(path, (1024, 768)).into_drawing_area();&#10;    root.fill(&amp;WHITE)?;&#10;&#10;    // Find min and max reward for y-axis&#10;    let max_val = data.iter().cloned().fold(f32::NEG_INFINITY, f32::max);&#10;    let min_val = data.iter().cloned().fold(f32::INFINITY, f32::min);&#10;&#10;    // Add some padding, but cap at reward limits&#10;    let y_max = (max_val + 0.2).min(1.0);&#10;    let y_min = (min_val - 0.2).max(-1.0);&#10;&#10;    let mut chart = ChartBuilder::on(&amp;root)&#10;        .caption(title, (&quot;sans-serif&quot;, 40).into_font())&#10;        .margin(10)&#10;        .x_label_area_size(40)&#10;        .y_label_area_size(40)&#10;        .build_cartesian_2d(0..data.len(), y_min..y_max)?;&#10;&#10;    chart.configure_mesh()&#10;        .x_desc(&quot;Trial Batch&quot;)&#10;        .y_desc(&quot;Average Reward&quot;)&#10;        .draw()?;&#10;&#10;    chart.draw_series(LineSeries::new(&#10;        data.iter().enumerate().map(|(x, y)| (x, *y)),&#10;        &amp;BLUE&#10;    ))?;&#10;&#10;    root.present()?;&#10;    println!(&quot;Reward plot saved to {}&quot;, path);&#10;    Ok(())&#10;}&#10;&#10;/// Plots two 1D vectors of f32 data overlaid as a line chart with legend.&#10;fn plot_two_series_over_time(&#10;    data1: &amp;[f32],&#10;    label1: &amp;str,&#10;    data2: &amp;[f32],&#10;    label2: &amp;str,&#10;    path: &amp;str,&#10;    title: &amp;str,&#10;) -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {&#10;    let len = data1.len().max(data2.len());&#10;    if len == 0 {&#10;        println!(&quot;No data to plot for {}&quot;, title);&#10;        return Ok(());&#10;    }&#10;&#10;    // Compute combined min/max for y-axis&#10;    let mut min_val = f32::INFINITY;&#10;    let mut max_val = f32::NEG_INFINITY;&#10;    for v in data1.iter().chain(data2.iter()) {&#10;        if *v &lt; min_val { min_val = *v; }&#10;        if *v &gt; max_val { max_val = *v; }&#10;    }&#10;    if !min_val.is_finite() || !max_val.is_finite() {&#10;        println!(&quot;Data contained non-finite values; skipping plot {}&quot;, title);&#10;        return Ok(());&#10;    }&#10;&#10;    let y_max = (max_val + 0.2).min(1.5);&#10;    let y_min = (min_val - 0.2).max(-1.5);&#10;&#10;    let root = BitMapBackend::new(path, (1024, 768)).into_drawing_area();&#10;    root.fill(&amp;WHITE)?;&#10;&#10;    let mut chart = ChartBuilder::on(&amp;root)&#10;        .caption(title, (&quot;sans-serif&quot;, 40).into_font())&#10;        .margin(10)&#10;        .x_label_area_size(40)&#10;        .y_label_area_size(50)&#10;        .build_cartesian_2d(0..len, y_min..y_max)?;&#10;&#10;    chart&#10;        .configure_mesh()&#10;        .x_desc(&quot;Step Index&quot;)&#10;        .y_desc(&quot;Value&quot;)&#10;        .draw()?;&#10;&#10;    // Series 1&#10;    chart&#10;        .draw_series(LineSeries::new(&#10;            (0..data1.len()).map(|i| (i, data1[i])),&#10;            &amp;BLUE,&#10;        ))?&#10;        .label(label1)&#10;        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], BLUE.stroke_width(2)));&#10;&#10;    // Series 2&#10;    chart&#10;        .draw_series(LineSeries::new(&#10;            (0..data2.len()).map(|i| (i, data2[i])),&#10;            &amp;RED,&#10;        ))?&#10;        .label(label2)&#10;        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], RED.stroke_width(2)));&#10;&#10;    chart&#10;        .configure_series_labels()&#10;        .border_style(&amp;BLACK)&#10;        .background_style(&amp;WHITE.mix(0.8))&#10;        .draw()?;&#10;&#10;    root.present()?;&#10;    println!(&quot;Combined plot saved to {}&quot;, path);&#10;    Ok(())&#10;}&#10;&#10;fn main() {&#10;    println!(&quot;Spiking Neural Network Simulation&quot;);&#10;    let mut rng = thread_rng(); // Non-deterministic seed for variability&#10;    let mut network = Network::create_dense(3, &amp;mut rng);&#10;    let mut simulation = Simulation::new(1.0, network.neurons.clone());&#10;&#10;    network.plot_synapse_weights(&quot;synapse_weights_start.png&quot;).unwrap();&#10;&#10;    const INPUT_NEURON_A_IDX: usize = 0; // &quot;Go&quot; signal&#10;    const INPUT_NEURON_B_IDX: usize = 1; // &quot;No-Go&quot; signal&#10;    const OUTPUT_NEURON_IDX: usize = 2; // Target output&#10;    const REWARD_MAGNITUDE: f32 = 1.0; // Changed to f32&#10;&#10;    const NUM_TRIALS: u32 = 20_000;&#10;    const TRIAL_WINDOW_STEPS: u32 = 25;&#10;&#10;    println!(&quot;Starting simulation... Target: Neuron {} spikes for Input {}, not for Input {}.&quot;,&#10;             OUTPUT_NEURON_IDX, INPUT_NEURON_A_IDX, INPUT_NEURON_B_IDX);&#10;    println!(&quot;Running {} trials, each with a {}-step response window.&quot;, NUM_TRIALS, TRIAL_WINDOW_STEPS);&#10;&#10;&#10;    let mut total_reward_batch = 0.0f32;&#10;    let mut all_trial_rewards: Vec&lt;f32&gt; = Vec::new();&#10;    let mut batch_avg_rewards: Vec&lt;f32&gt; = Vec::new();&#10;    // New series: RewardSystem EMA average per trial (sampled after applying reward)&#10;    let mut reward_system_avg_over_trials: Vec&lt;f32&gt; = Vec::new();&#10;    const BATCH_SIZE: u32 = 50;&#10;&#10;    for trial in 0..NUM_TRIALS {&#10;        let (input_idx, is_go_signal) = if rng.gen_bool(0.5) {&#10;            (INPUT_NEURON_A_IDX, true)&#10;        } else {&#10;            (INPUT_NEURON_B_IDX, false)&#10;        };&#10;&#10;        // Get spike time *before* the trial starts&#10;        let last_spike_time_before_trial = {&#10;            network.neurons[OUTPUT_NEURON_IDX].read().unwrap().time_of_last_fire()&#10;        };&#10;&#10;        // pct_rand should decrease exponentially over trials&#10;        let _pct_rand = (-0.3 * (trial as f32)).exp();&#10;&#10;        // --- This is the inner trial loop ---&#10;        simulation.step();&#10;        //simulation.random_noise(0.0, 1.0, 1.0, &amp;mut rng);&#10;        for _ in 0..TRIAL_WINDOW_STEPS {&#10;            simulation.input_external_stimuli(network.neurons[input_idx].clone(), 1.0);&#10;            //if pct_rand &gt; 0.0001 {&#10;            //    simulation.random_noise(-pct_rand*5.0, pct_rand*5.0, pct_rand, &amp;mut rng);&#10;            //}&#10;            simulation.step();&#10;            // DO NOT apply reward here&#10;        }&#10;        // --- End of inner trial loop ---&#10;&#10;        // Now, check the *overall* outcome of the trial&#10;        println!(&quot;Evaluating trial {}: Input Neuron {}, Go Signal: {}, Started at {}&quot;, trial + 1, input_idx, is_go_signal, last_spike_time_before_trial);&#10;&#10;        for fire in network.neurons[OUTPUT_NEURON_IDX].read().unwrap().last_spike_times.iter().filter(|p| p.time &gt; last_spike_time_before_trial) {&#10;            println!(&quot;  Output neuron spike at time {:.2} ms, strength: {}&quot;, fire.time, fire.membrane_potential_at_spike);&#10;        }&#10;&#10;        let output_spiked_during_trial = {&#10;            network.neurons[OUTPUT_NEURON_IDX].read().unwrap().time_of_last_fire() &gt; last_spike_time_before_trial&#10;        };&#10;        //println!(&quot;Output spiked during trial: {}&quot;, output_spiked_during_trial);&#10;&#10;        let reward: f32;&#10;        if is_go_signal {&#10;            if output_spiked_during_trial {&#10;                reward = REWARD_MAGNITUDE; // Correct: &quot;Go&quot; and it spiked&#10;            } else {&#10;                reward = -REWARD_MAGNITUDE; // Correct: &quot;Go&quot; and it didn't spike&#10;            }&#10;        } else { // is_no_go_signal&#10;            if output_spiked_during_trial {&#10;                reward = -REWARD_MAGNITUDE; // Correct: &quot;No-Go&quot; and it spiked&#10;            } else {&#10;                reward = REWARD_MAGNITUDE; // Correct: &quot;No-Go&quot; and it didn't spike&#10;            }&#10;        }&#10;&#10;        // Apply the *single* reward for the *entire* trial&#10;        simulation.reward(reward);&#10;&#10;        // Capture RewardSystem EMA average immediately after this trial's reward&#10;        reward_system_avg_over_trials.push(simulation.average_reward());&#10;&#10;        // This intra-trial result tracking is fine, but it was just for logging.&#10;        // We'll use the final reward for logging.&#10;        let intra_trial_result = reward;&#10;        all_trial_rewards.push(intra_trial_result);&#10;        total_reward_batch += intra_trial_result;&#10;&#10;        if (trial + 1) % BATCH_SIZE == 0 {&#10;            let avg_reward = total_reward_batch / (BATCH_SIZE as f32);&#10;            println!(&quot;Trials {}-{}: Average Reward = {:.2}&quot;, trial + 1 - BATCH_SIZE, trial + 1, avg_reward);&#10;            batch_avg_rewards.push(avg_reward);&#10;            total_reward_batch = 0.0f32;&#10;        }&#10;    }&#10;&#10;    println!(&quot;Simulation finished.&quot;);&#10;&#10;    if let Err(e) = plot_reward_over_time(&#10;        &amp;batch_avg_rewards,&#10;        &quot;reward_over_time.png&quot;,&#10;        &quot;Average Reward per Batch&quot;,&#10;    ) {&#10;        eprintln!(&quot;Error plotting reward: {}&quot;, e);&#10;    }&#10;&#10;    // Also plot the RewardSystem EMA average over trials&#10;    if let Err(e) = plot_reward_over_time(&#10;        &amp;reward_system_avg_over_trials,&#10;        &quot;reward_system_average_over_time.png&quot;,&#10;        &quot;EMA Average Reward (RewardSystem)&quot;,&#10;    ) {&#10;        eprintln!(&quot;Error plotting RewardSystem average: {}&quot;, e);&#10;    }&#10;&#10;    // New: plot delta error per learning step (one point per reward application)&#10;    let delta_errors: Vec&lt;f32&gt; = simulation.delta_error_history().to_vec();&#10;    if let Err(e) = plot_reward_over_time(&#10;        &amp;delta_errors,&#10;        &quot;delta_error_over_time.png&quot;,&#10;        &quot;Delta Error per Learning Step&quot;,&#10;    ) {&#10;        eprintln!(&quot;Error plotting delta error: {}&quot;, e);&#10;    }&#10;&#10;    // New: combined plot of EMA average reward and delta error in the same chart&#10;    if let Err(e) = plot_two_series_over_time(&#10;        &amp;reward_system_avg_over_trials,&#10;        &quot;EMA Avg Reward&quot;,&#10;        &amp;delta_errors,&#10;        &quot;Delta Error&quot;,&#10;        &quot;reward_and_delta_over_time.png&quot;,&#10;        &quot;EMA Average Reward and Delta Error&quot;,&#10;    ) {&#10;        eprintln!(&quot;Error plotting combined series: {}&quot;, e);&#10;    }&#10;&#10;    // ---&#10;&#10;    // Calculate and print moving average of rewards&#10;    let moving_avg_window = 100; // This is 100 *trials*, not batches&#10;    if all_trial_rewards.len() &gt; moving_avg_window {&#10;        println!(&quot;Moving average of reward (window={}):&quot;, moving_avg_window);&#10;        let moving_averages: Vec&lt;f32&gt; = all_trial_rewards // Changed to f32&#10;            .windows(moving_avg_window)&#10;            .map(|w| w.iter().sum::&lt;f32&gt;() / (moving_avg_window as f32)) // Changed to f32&#10;            .collect();&#10;&#10;        // Print a subset of moving averages to avoid flooding console&#10;        for (i, avg) in moving_averages.iter().enumerate().step_by(moving_avg_window) {&#10;            println!(&quot;  Trials {}-{}: {:.2}&quot;, i, i + moving_avg_window, avg);&#10;        }&#10;    }&#10;&#10;    network.plot_synapse_weights(&quot;synapse_weights_end.png&quot;).unwrap();&#10;    network.describe();&#10;&#10;    println!(&quot;\nCheck synapse_weights_start.png, synapse_weights_end.png, and reward_over_time.png.&quot;);&#10;    println!(&quot;If learning occurred, you should see a rising trend in the average rewards.&quot;);&#10;    println!(&quot;The weights plot might show stronger connections from {} -&gt; {}&quot;, INPUT_NEURON_A_IDX, OUTPUT_NEURON_IDX);&#10;    println!(&quot;and weaker (or inhibitory) connections from {} -&gt; {}&quot;, INPUT_NEURON_B_IDX, OUTPUT_NEURON_IDX);&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/simulation.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/simulation.rs" />
              <option name="originalContent" value="use crate::neuron::{Neuron, NeuronBehavior};&#10;use crate::reward_system::RewardSystem;&#10;use crate::spike_event::SpikeEvent;&#10;use crate::synapse::{Synapse};&#10;use rand::Rng;&#10;use std::collections::VecDeque;&#10;use std::sync::{Arc, RwLock};&#10;&#10;pub struct Simulation {&#10;    spike_queue: VecDeque&lt;Arc&lt;RwLock&lt;SpikeEvent&gt;&gt;&gt;,&#10;    dt: f32,&#10;    pub time: f32,&#10;    neurons: Vec&lt;Arc&lt;RwLock&lt;Neuron&gt;&gt;&gt;,&#10;    reward_system: RewardSystem,&#10;    current_trial_spike_events: Vec&lt;Arc&lt;RwLock&lt;SpikeEvent&gt;&gt;&gt;,&#10;}&#10;&#10;impl Simulation {&#10;    pub fn new(dt: f32, input_neurons: Vec&lt;Arc&lt;RwLock&lt;Neuron&gt;&gt;&gt;) -&gt; Self {&#10;        Simulation {&#10;            spike_queue: VecDeque::new(),&#10;            dt,&#10;            time: 0.0,&#10;            neurons: input_neurons,&#10;            reward_system: RewardSystem::new(),&#10;            current_trial_spike_events: Vec::new(),&#10;        }&#10;    }&#10;&#10;    pub fn reward(&amp;mut self, reward: f32) {&#10;        self.reward_system.add_reward(self.time, reward);&#10;        if self.current_trial_spike_events.is_empty() {&#10;            return;&#10;        }&#10;        self.reward_system&#10;            .update_synapses(self.time, &amp;self.current_trial_spike_events);&#10;        self.current_trial_spike_events = Vec::new();&#10;    }&#10;&#10;    // New: expose the reward system's EMA average reward at current sim time&#10;    pub fn average_reward(&amp;self) -&gt; f32 {&#10;        self.reward_system.get_average_reward(self.time).unwrap_or(0.0)&#10;    }&#10;&#10;    // New: expose delta error history for plotting&#10;    pub fn delta_error_history(&amp;self) -&gt; &amp;[f32] {&#10;        self.reward_system.delta_error_history()&#10;    }&#10;&#10;    fn send_action_potential(&amp;mut self, neuron: Arc&lt;RwLock&lt;Neuron&gt;&gt;) {&#10;        let n = neuron.read().unwrap();&#10;        for syn in &amp;n.exiting_synapses {&#10;            let wsyn = syn.write().unwrap();&#10;            let spike_event = Arc::new(RwLock::new(SpikeEvent {&#10;                synapse: syn.clone(),&#10;                delivery_time: self.time + wsyn.delay,&#10;                presynaptic_ema_firing_rate_before_spike: neuron.read().unwrap().ema_firing_rate_before_last_spike&#10;            }));&#10;            self.spike_queue.push_back(spike_event);&#10;        }&#10;    }&#10;&#10;    fn step_process_nodes(&amp;mut self, neurons: Vec&lt;Arc&lt;RwLock&lt;Neuron&gt;&gt;&gt;) {&#10;        let mut firing_neurons = Vec::with_capacity(neurons.len() * 5);&#10;        for neuron in &amp;neurons {&#10;            let fired = {&#10;                let mut n = neuron.write().unwrap();&#10;                n.step(self.time)&#10;            };&#10;            if fired {&#10;                // Neuron fired, create spike events&#10;                firing_neurons.push(neuron.clone());&#10;            }&#10;        }&#10;        for neuron in firing_neurons {&#10;            self.send_action_potential(neuron.clone());&#10;        }&#10;    }&#10;&#10;    pub fn input_external_stimuli(&amp;mut self, node: Arc&lt;RwLock&lt;Neuron&gt;&gt;, magnitude: f32) {&#10;        node.write().unwrap().receive(magnitude, self.time);&#10;        self.step_process_nodes(vec![node]);&#10;    }&#10;&#10;    pub fn random_noise(&amp;mut self, min: f32, max: f32, percent: f32, rng: &amp;mut impl Rng) {&#10;        // Adds random noise to a percentage of neurons&#10;        let num_neurons = (self.neurons.len() as f32 * percent).ceil() as usize;&#10;        let mut selected_indices = Vec::with_capacity(num_neurons);&#10;        let mut modified_neurons = Vec::with_capacity(num_neurons);&#10;        while selected_indices.len() &lt; num_neurons {&#10;            let idx = rng.gen_range(0..self.neurons.len());&#10;            if !selected_indices.contains(&amp;idx) {&#10;                selected_indices.push(idx);&#10;                self.neurons[idx]&#10;                    .write()&#10;                    .unwrap()&#10;                    .receive(rng.gen_range(min..max), self.time);&#10;                modified_neurons.push(self.neurons[idx].clone());&#10;            }&#10;        }&#10;        self.step_process_nodes(modified_neurons);&#10;    }&#10;&#10;    pub(crate) fn step(&amp;mut self) {&#10;        // Process external stimuli&#10;        self.time += self.dt;&#10;        self.process_events();&#10;    }&#10;&#10;    fn process_events(&amp;mut self) {&#10;        // May be roughly correct size&#10;        let mut new_firing_neurons = Vec::with_capacity(self.spike_queue.len() * 5);&#10;        while let Some(event) = self.spike_queue.front() {&#10;            let delivery_time = event.read().unwrap().delivery_time as f32;&#10;            if delivery_time &lt;= self.time {&#10;                let event = self.spike_queue.pop_front().unwrap();&#10;                let synapse = event.read().unwrap().synapse.clone();&#10;                let wsyn = synapse.write().unwrap();&#10;                let post_neuron = wsyn.get_postsynaptic_neuron();&#10;                let mut n = post_neuron.write().unwrap();&#10;                n.receive(wsyn.get_weight(), self.time);&#10;&#10;                if n.will_fire(delivery_time) {&#10;                    // Neuron fired, create spike events&#10;                    new_firing_neurons.push(post_neuron.clone());&#10;                    self.current_trial_spike_events.push(event)&#10;                }&#10;            } else {&#10;                break;&#10;            }&#10;        }&#10;&#10;        // Could be more optimized if we check for duplicated nodes in the new_firing_neurons&#10;        self.step_process_nodes(new_firing_neurons);&#10;    }&#10;}&#10;" />
              <option name="updatedContent" value="use crate::neuron::{Neuron, NeuronBehavior};&#10;use crate::reward_system::RewardSystem;&#10;use crate::spike_event::SpikeEvent;&#10;use crate::synapse::{Synapse};&#10;use rand::Rng;&#10;use std::collections::VecDeque;&#10;use std::sync::{Arc, RwLock};&#10;&#10;pub struct Simulation {&#10;    spike_queue: VecDeque&lt;Arc&lt;RwLock&lt;SpikeEvent&gt;&gt;&gt;,&#10;    dt: f32,&#10;    pub time: f32,&#10;    neurons: Vec&lt;Arc&lt;RwLock&lt;Neuron&gt;&gt;&gt;,&#10;    reward_system: RewardSystem,&#10;    current_trial_spike_events: Vec&lt;Arc&lt;RwLock&lt;SpikeEvent&gt;&gt;&gt;,&#10;}&#10;&#10;impl Simulation {&#10;    pub fn new(dt: f32, input_neurons: Vec&lt;Arc&lt;RwLock&lt;Neuron&gt;&gt;&gt;) -&gt; Self {&#10;        Simulation {&#10;            spike_queue: VecDeque::new(),&#10;            dt,&#10;            time: 0.0,&#10;            neurons: input_neurons,&#10;            reward_system: RewardSystem::new(),&#10;            current_trial_spike_events: Vec::new(),&#10;        }&#10;    }&#10;&#10;    pub fn reward(&amp;mut self, reward: f32) {&#10;        self.reward_system.add_reward(self.time, reward);&#10;        // Always call update_synapses to record delta error per learning step,&#10;        // even if there were no spike events (no weight updates will occur).&#10;        self.reward_system&#10;            .update_synapses(self.time, &amp;self.current_trial_spike_events);&#10;        self.current_trial_spike_events = Vec::new();&#10;    }&#10;&#10;    // New: expose the reward system's EMA average reward at current sim time&#10;    pub fn average_reward(&amp;self) -&gt; f32 {&#10;        self.reward_system.get_average_reward(self.time).unwrap_or(0.0)&#10;    }&#10;&#10;    // New: expose delta error history for plotting&#10;    pub fn delta_error_history(&amp;self) -&gt; &amp;[f32] {&#10;        self.reward_system.delta_error_history()&#10;    }&#10;&#10;    fn send_action_potential(&amp;mut self, neuron: Arc&lt;RwLock&lt;Neuron&gt;&gt;) {&#10;        let n = neuron.read().unwrap();&#10;        for syn in &amp;n.exiting_synapses {&#10;            let wsyn = syn.write().unwrap();&#10;            let spike_event = Arc::new(RwLock::new(SpikeEvent {&#10;                synapse: syn.clone(),&#10;                delivery_time: self.time + wsyn.delay,&#10;                presynaptic_ema_firing_rate_before_spike: neuron.read().unwrap().ema_firing_rate_before_last_spike&#10;            }));&#10;            self.spike_queue.push_back(spike_event);&#10;        }&#10;    }&#10;&#10;    fn step_process_nodes(&amp;mut self, neurons: Vec&lt;Arc&lt;RwLock&lt;Neuron&gt;&gt;&gt;) {&#10;        let mut firing_neurons = Vec::with_capacity(neurons.len() * 5);&#10;        for neuron in &amp;neurons {&#10;            let fired = {&#10;                let mut n = neuron.write().unwrap();&#10;                n.step(self.time)&#10;            };&#10;            if fired {&#10;                // Neuron fired, create spike events&#10;                firing_neurons.push(neuron.clone());&#10;            }&#10;        }&#10;        for neuron in firing_neurons {&#10;            self.send_action_potential(neuron.clone());&#10;        }&#10;    }&#10;&#10;    pub fn input_external_stimuli(&amp;mut self, node: Arc&lt;RwLock&lt;Neuron&gt;&gt;, magnitude: f32) {&#10;        node.write().unwrap().receive(magnitude, self.time);&#10;        self.step_process_nodes(vec![node]);&#10;    }&#10;&#10;    pub fn random_noise(&amp;mut self, min: f32, max: f32, percent: f32, rng: &amp;mut impl Rng) {&#10;        // Adds random noise to a percentage of neurons&#10;        let num_neurons = (self.neurons.len() as f32 * percent).ceil() as usize;&#10;        let mut selected_indices = Vec::with_capacity(num_neurons);&#10;        let mut modified_neurons = Vec::with_capacity(num_neurons);&#10;        while selected_indices.len() &lt; num_neurons {&#10;            let idx = rng.gen_range(0..self.neurons.len());&#10;            if !selected_indices.contains(&amp;idx) {&#10;                selected_indices.push(idx);&#10;                self.neurons[idx]&#10;                    .write()&#10;                    .unwrap()&#10;                    .receive(rng.gen_range(min..max), self.time);&#10;                modified_neurons.push(self.neurons[idx].clone());&#10;            }&#10;        }&#10;        self.step_process_nodes(modified_neurons);&#10;    }&#10;&#10;    pub(crate) fn step(&amp;mut self) {&#10;        // Process external stimuli&#10;        self.time += self.dt;&#10;        self.process_events();&#10;    }&#10;&#10;    fn process_events(&amp;mut self) {&#10;        // May be roughly correct size&#10;        let mut new_firing_neurons = Vec::with_capacity(self.spike_queue.len() * 5);&#10;        while let Some(event) = self.spike_queue.front() {&#10;            let delivery_time = event.read().unwrap().delivery_time as f32;&#10;            if delivery_time &lt;= self.time {&#10;                let event = self.spike_queue.pop_front().unwrap();&#10;                let synapse = event.read().unwrap().synapse.clone();&#10;                let wsyn = synapse.write().unwrap();&#10;                let post_neuron = wsyn.get_postsynaptic_neuron();&#10;                let mut n = post_neuron.write().unwrap();&#10;                n.receive(wsyn.get_weight(), self.time);&#10;&#10;                if n.will_fire(delivery_time) {&#10;                    // Neuron fired, create spike events&#10;                    new_firing_neurons.push(post_neuron.clone());&#10;                    self.current_trial_spike_events.push(event)&#10;                }&#10;            } else {&#10;                break;&#10;            }&#10;        }&#10;&#10;        // Could be more optimized if we check for duplicated nodes in the new_firing_neurons&#10;        self.step_process_nodes(new_firing_neurons);&#10;    }&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
        <entry key="$PROJECT_DIR$/src/testing.rs">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/src/testing.rs" />
              <option name="originalContent" value="use crate::constants::{STEPS_PER_IMAGE, STEP_SIZE_MS};&#10;use crate::network::Network;&#10;use indicatif::{ProgressBar, ProgressStyle};&#10;use rayon::prelude::ParallelIterator;&#10;use rayon::prelude::*;&#10;&#10;pub fn test_network(&#10;    network: &amp;Network,&#10;    test_set: &amp;[(Vec&lt;f64&gt;, usize)],&#10;    output_neuron_indices: &amp;[usize],&#10;) {&#10;    println!(&quot;\n--- Testing Phase ---&quot;);&#10;&#10;    // Pre-convert all test images to input vectors&#10;    println!(&quot;Pre-processing test images...&quot;);&#10;    let test_inputs: Vec&lt;(Vec&lt;Vec&lt;f64&gt;&gt;, usize)&gt; = test_set&#10;        .par_iter()&#10;        .map(|(img_data, label)| {&#10;            let input_vector: Vec&lt;Vec&lt;f64&gt;&gt; = (0..STEPS_PER_IMAGE)&#10;                .map(|_| {&#10;                    img_data&#10;                        .iter()&#10;                        .map(|&amp;pixel_val| pixel_val * 0.20)&#10;                        .collect()&#10;                })&#10;                .collect();&#10;            (input_vector, *label)&#10;        })&#10;        .collect();&#10;&#10;    let mut correct_predictions = 0;&#10;    let mut confusion_matrix = vec![vec![0; 2]; 2];&#10;&#10;    let test_pb = ProgressBar::new(test_inputs.len() as u64);&#10;    test_pb.set_style(&#10;        ProgressStyle::default_bar()&#10;            .template(&quot;[{elapsed_precise}] {bar:40.green/blue} {pos}/{len} {msg}&quot;)&#10;            .unwrap()&#10;            .progress_chars(&quot;##-&quot;),&#10;    );&#10;&#10;    for (input_vector, actual_label) in test_inputs.iter() {&#10;        let predicted_label =&#10;            network.predict(input_vector, STEPS_PER_IMAGE, STEP_SIZE_MS, output_neuron_indices);&#10;&#10;        confusion_matrix[*actual_label][predicted_label] += 1;&#10;&#10;        if predicted_label == *actual_label {&#10;            correct_predictions += 1;&#10;        }&#10;&#10;        test_pb.inc(1);&#10;    }&#10;    test_pb.finish_with_message(&quot;Testing complete&quot;);&#10;&#10;    let accuracy = (correct_predictions as f64 / test_inputs.len() as f64) * 100.0;&#10;&#10;    println!(&quot;\n--- Results ---&quot;);&#10;    println!(&#10;        &quot;Test Accuracy: {:.2}% ({}/{})&quot;,&#10;        accuracy,&#10;        correct_predictions,&#10;        test_inputs.len()&#10;    );&#10;&#10;    // Display confusion matrix&#10;    println!(&quot;\n--- Confusion Matrix ---&quot;);&#10;    println!(&quot;                  Predicted&quot;);&#10;    println!(&quot;                  Setosa  Versicolour&quot;);&#10;    println!(&#10;        &quot;Actual Setosa       {:&gt;3}      {:&gt;3}&quot;,&#10;        confusion_matrix[0][0], confusion_matrix[0][1]&#10;    );&#10;    println!(&#10;        &quot;       Versicolour  {:&gt;3}      {:&gt;3}&quot;,&#10;        confusion_matrix[1][0], confusion_matrix[1][1]&#10;    );&#10;}&#10;" />
              <option name="updatedContent" value="use crate::constants::{STEPS_PER_IMAGE, STEP_SIZE_MS};&#10;use crate::network::Network;&#10;use indicatif::{ProgressBar, ProgressStyle};&#10;use rayon::prelude::*;&#10;&#10;pub fn test_network(&#10;    network: &amp;Network,&#10;    test_set: &amp;[(Vec&lt;f64&gt;, usize)],&#10;    output_neuron_indices: &amp;[usize],&#10;) {&#10;    println!(&quot;\n--- Testing Phase ---&quot;);&#10;&#10;    // Pre-convert all test images to input vectors&#10;    println!(&quot;Pre-processing test images...&quot;);&#10;    let test_inputs: Vec&lt;(Vec&lt;Vec&lt;f64&gt;&gt;, usize)&gt; = test_set&#10;        .par_iter()&#10;        .map(|(img_data, label)| {&#10;            let input_vector: Vec&lt;Vec&lt;f64&gt;&gt; = (0..STEPS_PER_IMAGE)&#10;                .map(|_| {&#10;                    img_data&#10;                        .iter()&#10;                        .map(|&amp;pixel_val| pixel_val * 0.20)&#10;                        .collect()&#10;                })&#10;                .collect();&#10;            (input_vector, *label)&#10;        })&#10;        .collect();&#10;&#10;    let mut correct_predictions = 0;&#10;    let mut confusion_matrix = vec![vec![0; 2]; 2];&#10;    let mut printed_setosa = 0;&#10;    let mut printed_versicolour = 0;&#10;    const MAX_PRINTS_PER_CLASS: usize = 2;&#10;&#10;    let test_pb = ProgressBar::new(test_inputs.len() as u64);&#10;    test_pb.set_style(&#10;        ProgressStyle::default_bar()&#10;            .template(&quot;[{elapsed_precise}] {bar:40.green/blue} {pos}/{len} {msg}&quot;)&#10;            .unwrap()&#10;            .progress_chars(&quot;##-&quot;),&#10;    );&#10;&#10;    for (i, (input_vector, actual_label)) in test_inputs.iter().enumerate() {&#10;        let (predicted_label, membrane_potentials) =&#10;            network.predict(input_vector, STEPS_PER_IMAGE, STEP_SIZE_MS, output_neuron_indices);&#10;&#10;        confusion_matrix[*actual_label][predicted_label] += 1;&#10;&#10;        if predicted_label == *actual_label {&#10;            correct_predictions += 1;&#10;        }&#10;&#10;        // Print membrane potentials for a few samples&#10;        let class_name = if *actual_label == 0 { &quot;Setosa&quot; } else { &quot;Versicolour&quot; };&#10;        if *actual_label == 0 &amp;&amp; printed_setosa &lt; MAX_PRINTS_PER_CLASS {&#10;            let plot_filename = format!(&quot;membrane_potential_setosa_{}.png&quot;, i);&#10;            println!(&quot;\n--- Sample: {} (Actual) ---&quot;, class_name);&#10;            println!(&quot;Predicted: {}&quot;, if predicted_label == 0 { &quot;Setosa&quot; } else { &quot;Versicolour&quot; });&#10;            network.plot_membrane_potentials(&amp;membrane_potentials, &amp;plot_filename, output_neuron_indices).unwrap();&#10;            println!(&quot;Membrane potential plot saved to {}&quot;, plot_filename);&#10;            printed_setosa += 1;&#10;        } else if *actual_label == 1 &amp;&amp; printed_versicolour &lt; MAX_PRINTS_PER_CLASS {&#10;            let plot_filename = format!(&quot;membrane_potential_versicolour_{}.png&quot;, i);&#10;            println!(&quot;\n--- Sample: {} (Actual) ---&quot;, class_name);&#10;            println!(&quot;Predicted: {}&quot;, if predicted_label == 1 { &quot;Versicolour&quot; } else { &quot;Setosa&quot; });&#10;            network.plot_membrane_potentials(&amp;membrane_potentials, &amp;plot_filename, output_neuron_indices).unwrap();&#10;            println!(&quot;Membrane potential plot saved to {}&quot;, plot_filename);&#10;            printed_versicolour += 1;&#10;        }&#10;&#10;        test_pb.inc(1);&#10;    }&#10;    test_pb.finish_with_message(&quot;Testing complete&quot;);&#10;&#10;    let accuracy = (correct_predictions as f64 / test_inputs.len() as f64) * 100.0;&#10;&#10;    println!(&quot;\n--- Results ---&quot;);&#10;    println!(&#10;        &quot;Test Accuracy: {:.2}% ({}/{})&quot;,&#10;        accuracy,&#10;        correct_predictions,&#10;        test_inputs.len()&#10;    );&#10;&#10;    // Display confusion matrix&#10;    println!(&quot;\n--- Confusion Matrix ---&quot;);&#10;    println!(&quot;                  Predicted&quot;);&#10;    println!(&quot;                  Setosa  Versicolour&quot;);&#10;    println!(&#10;        &quot;Actual Setosa       {:&gt;3}      {:&gt;3}&quot;,&#10;        confusion_matrix[0][0], confusion_matrix[0][1]&#10;    );&#10;    println!(&#10;        &quot;       Versicolour  {:&gt;3}      {:&gt;3}&quot;,&#10;        confusion_matrix[1][0], confusion_matrix[1][1]&#10;    );&#10;}" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>